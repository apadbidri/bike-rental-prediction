{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, suppose you are a data scientist working for a city's government. They are interested in boosting levels of cycling, and want to make sure enough bikes are available for the public at any given time. You have been tasked with building a neural network model to predict the total number of bike rentals in the city, based on historical data. We have provided you with data recorded at the hour-level, which includes variables such as the weather, temperature, and time of day.\n",
    "\n",
    "Your model should be designed to predict the total number of city bike rentals, on an hourly basis (i.e. each observation in the test/train data is the total number of bikes being rented for a given hour). You should therefore focus on predicting the variable 'cnt' -- which is the total count of rentals.\n",
    "\n",
    "Further information on this dataset, including variable descriptions, can be found on the UCI Machine Learning Repository here (https://archive.ics.uci.edu/dataset/275/bike+sharing+dataset). You should read this description carefully, and be mindful of your choice of variables etc.\n",
    "\n",
    "We have separated out a random test set from this data. Your goal is to train as predictive a model as possible using the provided formative_train.csv file. Once you are happy with your model, you should then predict the values for the formative_test.csv file. Note this file does not contain values for the outcome of interest.\n",
    "\n",
    "Specifically, you should:\n",
    "\n",
    "Define a neural network model class called my475_mod that is capable of taking in data, passing it through a neural network, and outputting a prediction.\n",
    "You may rely on functions outside this class definition to help you build/train the model\n",
    "Train an instance of that model on the provided training data and save your final trained model checkpoint to a file (this file should be named \"<CANDIDATE_NUMER>.pt\")\n",
    "Pass our test data--formative_test.csv--through your trained model and save the predictions as a .csv file. The file should contain a single column of predictions, with each row corresponding to a row in the test data. The first row should contain the header \"prediction\". Save this file as \"<CANDIDATE_NUMER>.csv\"\n",
    "We will assess both the quality of your code (i.e. the legibility of your definitions, the soundness of the architecture etc.) and the performance of your model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       dteday  season  yr  mnth  hr  holiday  weekday  workingday  weathersit  \\\n",
      "0  2012-06-06       2   1     6   4        0        3           1           1   \n",
      "1  2012-03-25       2   1     3   3        0        0           0           3   \n",
      "2  2011-02-14       1   0     2  15        0        1           1           1   \n",
      "3  2011-12-22       1   0    12   2        0        4           1           1   \n",
      "4  2011-12-10       4   0    12   0        0        6           0           2   \n",
      "\n",
      "   temp   atemp   hum  windspeed  casual  registered  cnt  \n",
      "0  0.46  0.4545  0.82     0.1045       3           7   10  \n",
      "1  0.42  0.4242  0.94     0.2985       8          10   18  \n",
      "2  0.56  0.5303  0.21     0.6567      19          71   90  \n",
      "3  0.48  0.4697  0.82     0.1045       1          10   11  \n",
      "4  0.26  0.2727  0.81     0.1045      11          66   77  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "# Replace the path with the actual path to your formative_train.csv file\n",
    "train_data = pd.read_csv('/Users/alyssapadbidri/Local/bike-rental-prediction/data/formative_train.csv')\n",
    "\n",
    "# Display the first few rows to ensure it's loaded correctly\n",
    "print(train_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the data\n",
    "train_data = pd.read_csv('/Users/alyssapadbidri/Local/bike-rental-prediction/data/formative_train.csv')\n",
    "test_data = pd.read_csv('/Users/alyssapadbidri/Local/bike-rental-prediction/data/formative_test.csv')\n",
    "\n",
    "# Remove 'dteday' column from both train and test data\n",
    "train_data = train_data.drop('dteday', axis=1)\n",
    "test_data = test_data.drop('dteday', axis=1)\n",
    "\n",
    "# Extract features and target\n",
    "X = train_data.drop('cnt', axis=1)  # All columns except 'cnt' are features\n",
    "y = train_data['cnt']  # Target variable is 'cnt'\n",
    "\n",
    "# Standardize the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split data into training and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the model\n",
    "class My475Model(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(My475Model, self).__init__()\n",
    "        # Define layers of the neural network\n",
    "        self.layer1 = nn.Linear(input_dim, 64)  # Input layer to hidden layer (64 neurons)\n",
    "        self.layer2 = nn.Linear(64, 32)         # Hidden layer (32 neurons)\n",
    "        self.output_layer = nn.Linear(32, 1)    # Output layer with 1 output (cnt)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Define the forward pass through the layers with ReLU activation\n",
    "        x = torch.relu(self.layer1(x))\n",
    "        x = torch.relu(self.layer2(x))\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the model\n",
    "input_dim = X_train.shape[1]  # Number of features\n",
    "model = My475Model(input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 68449.890625\n",
      "Epoch 11/100, Loss: 68322.75\n",
      "Epoch 21/100, Loss: 68139.3515625\n",
      "Epoch 31/100, Loss: 67860.0078125\n",
      "Epoch 41/100, Loss: 67435.6875\n",
      "Epoch 51/100, Loss: 66807.359375\n",
      "Epoch 61/100, Loss: 65900.7265625\n",
      "Epoch 71/100, Loss: 64628.05859375\n",
      "Epoch 81/100, Loss: 62894.5546875\n",
      "Epoch 91/100, Loss: 60605.80078125\n"
     ]
    }
   ],
   "source": [
    "# Convert the data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# Set up the loss function and optimizer\n",
    "criterion = nn.MSELoss()  # Mean Squared Error Loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "epochs = 100  # Number of epochs to train\n",
    "for epoch in range(epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    optimizer.zero_grad()  # Zero the gradients\n",
    "\n",
    "    # Forward pass\n",
    "    y_pred = model(X_train_tensor)\n",
    "\n",
    "    # Calculate the loss\n",
    "    loss = criterion(y_pred, y_train_tensor)\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print the loss every 10 epochs\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 58181.08984375\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    y_val_pred = model(X_val_tensor)\n",
    "    val_loss = criterion(y_val_pred, y_val_tensor)\n",
    "\n",
    "print(f'Validation Loss: {val_loss.item()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
